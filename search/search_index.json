{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Argo Events What is Argo Events? Argo Events is an event-based dependency manager for Kubernetes which helps you define multiple dependencies from a variety of event sources like webhook, s3, schedules, streams etc. and trigger Kubernetes objects after successful event dependencies resolution. Features Manage dependencies from a variety of event sources. Ability to customize business-level constraint logic for event dependencies resolution. Manage everything from simple, linear, real-time dependencies to complex, multi-source, batch job dependencies. Ability to extends framework to add your own event source listener. Define arbitrary boolean logic to resolve event dependencies. CloudEvents compliant. Ability to manage event sources at runtime. Event Listeners AMQP AWS SNS AWS SQS Cron Schedules GCP PubSub GitHub GitLab HDFS File Based Events Kafka Minio NATS MQTT K8s Resources Slack NetApp StorageGrid Webhooks","title":"Overview"},{"location":"#argo-events","text":"","title":"Argo Events"},{"location":"#what-is-argo-events","text":"Argo Events is an event-based dependency manager for Kubernetes which helps you define multiple dependencies from a variety of event sources like webhook, s3, schedules, streams etc. and trigger Kubernetes objects after successful event dependencies resolution.","title":"What is Argo Events?"},{"location":"#features","text":"Manage dependencies from a variety of event sources. Ability to customize business-level constraint logic for event dependencies resolution. Manage everything from simple, linear, real-time dependencies to complex, multi-source, batch job dependencies. Ability to extends framework to add your own event source listener. Define arbitrary boolean logic to resolve event dependencies. CloudEvents compliant. Ability to manage event sources at runtime.","title":"Features"},{"location":"#event-listeners","text":"AMQP AWS SNS AWS SQS Cron Schedules GCP PubSub GitHub GitLab HDFS File Based Events Kafka Minio NATS MQTT K8s Resources Slack NetApp StorageGrid Webhooks","title":"Event Listeners"},{"location":"controllers/","text":"Controllers Sensor and Gateway controllers are the components which manage Sensor and Gateway objects respectively. Sensor and Gateway are Kubernetes Custom Resources. For more information on K8 CRDs visit here. Controller Configmap Defines the instance-id and the namespace for the controller. e.g. # The gateway-controller configmap includes configuration information for the gateway-controller apiVersion : v1 kind : ConfigMap metadata : name : gateway-controller-configmap data : config : | instanceID: argo-events # mandatory namespace: my-custom-namespace # optional namespace : If you don't provide namespace, controller will watch all namespaces for gateway resource. instanceID : it is used to map a gateway or sensor object to a controller. e.g. when you create a gateway with label gateways.argoproj.io/gateway-controller-instanceid: argo-events , a controller with label argo-events will process that gateway. instanceID is used to horizontally scale controllers, so you won't end up overwhelming a single controller with large number of gateways or sensors. Also keep in mind that instanceID has nothing to do with namespace where you are deploying controllers and gateways/sensors objects.","title":"Controllers"},{"location":"controllers/#controllers","text":"Sensor and Gateway controllers are the components which manage Sensor and Gateway objects respectively. Sensor and Gateway are Kubernetes Custom Resources. For more information on K8 CRDs visit here.","title":"Controllers"},{"location":"controllers/#controller-configmap","text":"Defines the instance-id and the namespace for the controller. e.g. # The gateway-controller configmap includes configuration information for the gateway-controller apiVersion : v1 kind : ConfigMap metadata : name : gateway-controller-configmap data : config : | instanceID: argo-events # mandatory namespace: my-custom-namespace # optional namespace : If you don't provide namespace, controller will watch all namespaces for gateway resource. instanceID : it is used to map a gateway or sensor object to a controller. e.g. when you create a gateway with label gateways.argoproj.io/gateway-controller-instanceid: argo-events , a controller with label argo-events will process that gateway. instanceID is used to horizontally scale controllers, so you won't end up overwhelming a single controller with large number of gateways or sensors. Also keep in mind that instanceID has nothing to do with namespace where you are deploying controllers and gateways/sensors objects.","title":"Controller Configmap"},{"location":"developer_guide/","text":"Developer Guide Setup your DEV environment Argo Events is native to Kubernetes so you'll need a running Kubernetes cluster. This guide includes steps for Minikube for local development, but if you have another cluster you can ignore the Minikube specific step 3. Requirements Golang 1.11 Docker dep Installation Setup 1. Get the project go get github.com/argoproj/argo-events cd $GOPATH/src/github.com/argoproj/argo-events 2. Vendor dependencies dep ensure -vendor-only 3. Start Minikube and point Docker Client to Minikube's Docker Daemon minikube start eval $(minikube docker-env) 5. Build the project make all Changing Types If you're making a change to the pkg/apis package, please ensure you re-run the K8 code-generator scripts found in the /hack folder. First, ensure you have the generate-groups.sh script at the path: vendor/k8s.io/code-generator/ . Next run the following commands in order: $ make codegen How to write a custom gateway? To implement a custom gateway, you need to create a gRPC server and implement the service defined below. The framework code acts as a gRPC client consuming event stream from gateway server. Proto Definition The proto file is located here If you choose to implement the gateway in Go , then you can find generated client stubs here To create stubs in other languages, head over to gRPC website Service, /** * Service for handling event sources. */ service Eventing { // StartEventSource starts an event source and returns stream of events . rpc StartEventSource ( EventSource ) returns ( stream Event ) ; // ValidateEventSource validates an event source . rpc ValidateEventSource ( EventSource ) returns ( ValidEventSource ) ; } Available Environment Variables to Server Field Description GATEWAY_NAMESPACE K8s namespace of the gateway GATEWAY_EVENT_SOURCE_CONFIG_MAP K8s configmap containing event source GATEWAY_NAME name of the gateway GATEWAY_CONTROLLER_INSTANCE_ID gateway controller instance id GATEWAY_CONTROLLER_NAME gateway controller name GATEWAY_SERVER_PORT Port on which the gateway gRPC server should run","title":"Developer Guide"},{"location":"developer_guide/#developer-guide","text":"","title":"Developer Guide"},{"location":"developer_guide/#setup-your-dev-environment","text":"Argo Events is native to Kubernetes so you'll need a running Kubernetes cluster. This guide includes steps for Minikube for local development, but if you have another cluster you can ignore the Minikube specific step 3.","title":"Setup your DEV environment"},{"location":"developer_guide/#requirements","text":"Golang 1.11 Docker dep","title":"Requirements"},{"location":"developer_guide/#installation-setup","text":"","title":"Installation &amp; Setup"},{"location":"developer_guide/#1-get-the-project","text":"go get github.com/argoproj/argo-events cd $GOPATH/src/github.com/argoproj/argo-events","title":"1. Get the project"},{"location":"developer_guide/#2-vendor-dependencies","text":"dep ensure -vendor-only","title":"2. Vendor dependencies"},{"location":"developer_guide/#3-start-minikube-and-point-docker-client-to-minikubes-docker-daemon","text":"minikube start eval $(minikube docker-env)","title":"3. Start Minikube and point Docker Client to Minikube's Docker Daemon"},{"location":"developer_guide/#5-build-the-project","text":"make all","title":"5. Build the project"},{"location":"developer_guide/#changing-types","text":"If you're making a change to the pkg/apis package, please ensure you re-run the K8 code-generator scripts found in the /hack folder. First, ensure you have the generate-groups.sh script at the path: vendor/k8s.io/code-generator/ . Next run the following commands in order: $ make codegen","title":"Changing Types"},{"location":"developer_guide/#how-to-write-a-custom-gateway","text":"To implement a custom gateway, you need to create a gRPC server and implement the service defined below. The framework code acts as a gRPC client consuming event stream from gateway server.","title":"How to write a custom gateway?"},{"location":"developer_guide/#proto-definition","text":"The proto file is located here If you choose to implement the gateway in Go , then you can find generated client stubs here To create stubs in other languages, head over to gRPC website Service, /** * Service for handling event sources. */ service Eventing { // StartEventSource starts an event source and returns stream of events . rpc StartEventSource ( EventSource ) returns ( stream Event ) ; // ValidateEventSource validates an event source . rpc ValidateEventSource ( EventSource ) returns ( ValidEventSource ) ; }","title":"Proto Definition"},{"location":"developer_guide/#available-environment-variables-to-server","text":"Field Description GATEWAY_NAMESPACE K8s namespace of the gateway GATEWAY_EVENT_SOURCE_CONFIG_MAP K8s configmap containing event source GATEWAY_NAME name of the gateway GATEWAY_CONTROLLER_INSTANCE_ID gateway controller instance id GATEWAY_CONTROLLER_NAME gateway controller name GATEWAY_SERVER_PORT Port on which the gateway gRPC server should run","title":"Available Environment Variables to Server"},{"location":"getting_started/","text":"Getting Started We are going to set up a gateway, sensor and event-source for webhook. The goal is to trigger an Argo workflow upon a HTTP Post request. First, we need to setup event sources for gateway to listen. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/event-sources/webhook.yaml The event-source drives the configuration required for a gateway to consume events from external sources. Create webhook gateway, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/gateways/webhook.yaml After running above command, gateway controller will create corresponding a pod and service. Create webhook sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/sensors/webhook.yaml Once sensor object is created, sensor controller will create corresponding pod and service. Once the gateway and sensor pods are running, dispatch a HTTP POST request to /example endpoint. Note: the WEBHOOK_SERVICE_URL will differ based on the Kubernetes cluster. export WEBHOOK_SERVICE_URL=$(minikube service -n argo-events --url webhook-gateway-svc) echo $WEBHOOK_SERVICE_URL curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST $WEBHOOK_SERVICE_URL/example Note : If you are facing an issue getting service url by running minikube service -n argo-events --url webhook-gateway-svc You can use port forwarding to access the service as well, kubectl port-forward Open another terminal window and enter kubectl port-forward -n argo-events name_of_the_webhook_gateway_pod 12000:12000 You can now use localhost:12000 to query webhook gateway Verify that an Argo workflow was triggered. kubectl -n argo-events get workflows | grep webhook","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"We are going to set up a gateway, sensor and event-source for webhook. The goal is to trigger an Argo workflow upon a HTTP Post request. First, we need to setup event sources for gateway to listen. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/event-sources/webhook.yaml The event-source drives the configuration required for a gateway to consume events from external sources. Create webhook gateway, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/gateways/webhook.yaml After running above command, gateway controller will create corresponding a pod and service. Create webhook sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/sensors/webhook.yaml Once sensor object is created, sensor controller will create corresponding pod and service. Once the gateway and sensor pods are running, dispatch a HTTP POST request to /example endpoint. Note: the WEBHOOK_SERVICE_URL will differ based on the Kubernetes cluster. export WEBHOOK_SERVICE_URL=$(minikube service -n argo-events --url webhook-gateway-svc) echo $WEBHOOK_SERVICE_URL curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST $WEBHOOK_SERVICE_URL/example Note : If you are facing an issue getting service url by running minikube service -n argo-events --url webhook-gateway-svc You can use port forwarding to access the service as well, kubectl port-forward Open another terminal window and enter kubectl port-forward -n argo-events name_of_the_webhook_gateway_pod 12000:12000 You can now use localhost:12000 to query webhook gateway Verify that an Argo workflow was triggered. kubectl -n argo-events get workflows | grep webhook","title":"Getting Started"},{"location":"installation/","text":"Installation Requirements Kubernetes cluster v1.9 Installed the kubectl command-line tool v1.9.0 Using Helm Chart Note: This method does not work with Helm 3, only Helm 2. Make sure you have helm client installed and Tiller server is running. To install helm, follow the link. Add argoproj repository helm repo add argo https://argoproj.github.io/argo-helm Install argo-events chart helm install argo/argo-events Using kubectl One Command Installation Deploy Argo Events SA, Roles, ConfigMap, Sensor Controller and Gateway Controller kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/installation.yaml Step-by-Step Installation Create the namespace kubectl create namespace argo-events Create the service account kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-sa.yaml Create the cluster roles kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-cluster-roles.yaml Install the sensor custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-crd.yaml Install the gateway custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-crd.yaml Create the confimap for sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-configmap.yaml Create the configmap for gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-configmap.yaml Deploy the sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-deployment.yaml Deploy the gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-deployment.yaml Deploy at cluster level To deploy Argo-Events controllers at cluster level where the controllers will be able to process gateway and sensor objects created in any namespace, Make sure to apply cluster role and binding to the service account, kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-cluster-roles.yaml Update the configmap for both gateway and sensor and remove the namespace key from it. Deploy both gateway and sensor controllers and watch the magic.","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#requirements","text":"Kubernetes cluster v1.9 Installed the kubectl command-line tool v1.9.0","title":"Requirements"},{"location":"installation/#using-helm-chart","text":"Note: This method does not work with Helm 3, only Helm 2. Make sure you have helm client installed and Tiller server is running. To install helm, follow the link. Add argoproj repository helm repo add argo https://argoproj.github.io/argo-helm Install argo-events chart helm install argo/argo-events","title":"Using Helm Chart"},{"location":"installation/#using-kubectl","text":"","title":"Using kubectl"},{"location":"installation/#one-command-installation","text":"Deploy Argo Events SA, Roles, ConfigMap, Sensor Controller and Gateway Controller kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/installation.yaml","title":"One Command Installation"},{"location":"installation/#step-by-step-installation","text":"Create the namespace kubectl create namespace argo-events Create the service account kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-sa.yaml Create the cluster roles kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-cluster-roles.yaml Install the sensor custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-crd.yaml Install the gateway custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-crd.yaml Create the confimap for sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-configmap.yaml Create the configmap for gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-configmap.yaml Deploy the sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-deployment.yaml Deploy the gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-deployment.yaml","title":"Step-by-Step Installation"},{"location":"installation/#deploy-at-cluster-level","text":"To deploy Argo-Events controllers at cluster level where the controllers will be able to process gateway and sensor objects created in any namespace, Make sure to apply cluster role and binding to the service account, kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-cluster-roles.yaml Update the configmap for both gateway and sensor and remove the namespace key from it. Deploy both gateway and sensor controllers and watch the magic.","title":"Deploy at cluster level"},{"location":"concepts/event_source/","text":"Event Source Event Source are configuration store for a gateway to select from. The configuration stored in an Event Source is used by a gateway to consume events from external entities like AWS SNS, SQS, GCP PubSub, Webhooks etc. Specification Complete specification is available here .","title":"Event Source"},{"location":"concepts/event_source/#event-source","text":"Event Source are configuration store for a gateway to select from. The configuration stored in an Event Source is used by a gateway to consume events from external entities like AWS SNS, SQS, GCP PubSub, Webhooks etc.","title":"Event Source"},{"location":"concepts/event_source/#specification","text":"Complete specification is available here .","title":"Specification"},{"location":"concepts/gateway/","text":"Gateway What is a gateway? A gateway consumes events from outside entities, transforms them into the cloudevents specification compliant events and dispatches them to sensors. Relation between Gateway Event Source Event Source are event configuration store for a gateway. The configuration stored in an Event Source is used by a gateway to consume events from external entities like AWS SNS, SQS, GCP PubSub, Webhooks etc. Specification Complete specification is available here","title":"Gateway"},{"location":"concepts/gateway/#gateway","text":"","title":"Gateway"},{"location":"concepts/gateway/#what-is-a-gateway","text":"A gateway consumes events from outside entities, transforms them into the cloudevents specification compliant events and dispatches them to sensors.","title":"What is a gateway?"},{"location":"concepts/gateway/#relation-between-gateway-event-source","text":"Event Source are event configuration store for a gateway. The configuration stored in an Event Source is used by a gateway to consume events from external entities like AWS SNS, SQS, GCP PubSub, Webhooks etc.","title":"Relation between Gateway &amp; Event Source"},{"location":"concepts/gateway/#specification","text":"Complete specification is available here","title":"Specification"},{"location":"concepts/parameterization/","text":"Trigger Parameterization Payload of an event can be passed to any trigger. Argo Events offers parameterization at two levels, 1) Template 2) Resource Template You can parameterize the template that refers the Argo Worflow / K8s artifact. Resource Allows to parameterize the Argo workflow/K8s resource definition. You can find an example here. Parameter Structure A parameter contains: src : event : the name of the event dependency path : a key within event payload to look for value : default value if sensor can't find path in event payload dest : destination key within resource definition whose corresponding value needs to be replaced with value from event payload operation : what to do with the existing value at dest , either overwrite , prepend , or append","title":"Trigger Parameterization"},{"location":"concepts/parameterization/#trigger-parameterization","text":"Payload of an event can be passed to any trigger. Argo Events offers parameterization at two levels, 1) Template 2) Resource","title":"Trigger Parameterization"},{"location":"concepts/parameterization/#template","text":"You can parameterize the template that refers the Argo Worflow / K8s artifact.","title":"Template"},{"location":"concepts/parameterization/#resource","text":"Allows to parameterize the Argo workflow/K8s resource definition. You can find an example here.","title":"Resource"},{"location":"concepts/parameterization/#parameter-structure","text":"A parameter contains: src : event : the name of the event dependency path : a key within event payload to look for value : default value if sensor can't find path in event payload dest : destination key within resource definition whose corresponding value needs to be replaced with value from event payload operation : what to do with the existing value at dest , either overwrite , prepend , or append","title":"Parameter Structure"},{"location":"concepts/sensor/","text":"Sensor Sensors define a set of event dependencies (inputs) and triggers (outputs). What is an event dependency? A dependency is an event the sensor is expecting to happen. It is defined as \"gateway-name:event-source-name\". Also, you can use globs to catch a set of events (e.g. \"gateway-name:*\"). Specification Complete specification is available here .","title":"Sensor"},{"location":"concepts/sensor/#sensor","text":"Sensors define a set of event dependencies (inputs) and triggers (outputs).","title":"Sensor"},{"location":"concepts/sensor/#what-is-an-event-dependency","text":"A dependency is an event the sensor is expecting to happen. It is defined as \"gateway-name:event-source-name\". Also, you can use globs to catch a set of events (e.g. \"gateway-name:*\").","title":"What is an event dependency?"},{"location":"concepts/sensor/#specification","text":"Complete specification is available here .","title":"Specification"},{"location":"concepts/trigger/","text":"Trigger What is a trigger? Trigger is the resource executed by sensor once the event dependencies are resolved. Any K8s resource can act as a trigger (Custom Resources included). How to define a trigger? The framework provides support to fetch trigger resources from different sources. Inline Inlined artifacts are included directly within the sensor resource and decoded as a string. Example S3 Argo Events uses the minio-go client for access to any Amazon S3 compatible object store. Example File Artifacts are defined in a file that is mounted via a PersistentVolume within the sensor-controller pod. Example URL Artifacts are accessed from web via RESTful API. Example Configmap Artifacts stored in Kubernetes configmap are accessed using the key. Example Git Artifacts stored in either public or private Git repository. Example Resource Artifacts defined as generic K8s resource template. This is specially useful if you use tools like Kustomize to generate the sensor spec. What resource types are supported out of box? Argo Workflow Standard K8s resources Gateway Sensor How to trigger standard Kubernetes Resource instead of Argo Workflow? There could be a case where you may want to trigger a standard Kubernetes resource like Pod, Deployment etc. instead of an Argo Workflow. The sensor allows you to trigger any K8s resource the same way you would trigger an Argo Workflow. The example showcases how you can trigger different standard K8s resources. You can find K8s API reference here . To trigger other standard K8s resources, change the group and version in triggers/resource accordingly. How can I add my custom resource as trigger? The set of currently supported resources are implemented in the store package. You need to register your custom resource in order for sensor to be able to trigger it. Once you register your custom resource, you'll need to rebuild the sensor image. Follow these steps, Go to store.go in store package. Import your custom resource api package. In init method, add the scheme to your custom resource api. Make sure there are no errors. Rebuild the sensor binary using make sensor To build the image, first change IMAGE_NAMESPACE in Makefile to your docker registry and then run make sensor-image .","title":"Trigger"},{"location":"concepts/trigger/#trigger","text":"","title":"Trigger"},{"location":"concepts/trigger/#what-is-a-trigger","text":"Trigger is the resource executed by sensor once the event dependencies are resolved. Any K8s resource can act as a trigger (Custom Resources included).","title":"What is a trigger?"},{"location":"concepts/trigger/#how-to-define-a-trigger","text":"The framework provides support to fetch trigger resources from different sources.","title":"How to define a trigger?"},{"location":"concepts/trigger/#inline","text":"Inlined artifacts are included directly within the sensor resource and decoded as a string. Example","title":"Inline"},{"location":"concepts/trigger/#s3","text":"Argo Events uses the minio-go client for access to any Amazon S3 compatible object store. Example","title":"S3"},{"location":"concepts/trigger/#file","text":"Artifacts are defined in a file that is mounted via a PersistentVolume within the sensor-controller pod. Example","title":"File"},{"location":"concepts/trigger/#url","text":"Artifacts are accessed from web via RESTful API. Example","title":"URL"},{"location":"concepts/trigger/#configmap","text":"Artifacts stored in Kubernetes configmap are accessed using the key. Example","title":"Configmap"},{"location":"concepts/trigger/#git","text":"Artifacts stored in either public or private Git repository. Example","title":"Git"},{"location":"concepts/trigger/#resource","text":"Artifacts defined as generic K8s resource template. This is specially useful if you use tools like Kustomize to generate the sensor spec.","title":"Resource"},{"location":"concepts/trigger/#what-resource-types-are-supported-out-of-box","text":"Argo Workflow Standard K8s resources Gateway Sensor","title":"What resource types are supported out of box?"},{"location":"concepts/trigger/#how-to-trigger-standard-kubernetes-resource-instead-of-argo-workflow","text":"There could be a case where you may want to trigger a standard Kubernetes resource like Pod, Deployment etc. instead of an Argo Workflow. The sensor allows you to trigger any K8s resource the same way you would trigger an Argo Workflow. The example showcases how you can trigger different standard K8s resources. You can find K8s API reference here . To trigger other standard K8s resources, change the group and version in triggers/resource accordingly.","title":"How to trigger standard Kubernetes Resource instead of Argo Workflow?"},{"location":"concepts/trigger/#how-can-i-add-my-custom-resource-as-trigger","text":"The set of currently supported resources are implemented in the store package. You need to register your custom resource in order for sensor to be able to trigger it. Once you register your custom resource, you'll need to rebuild the sensor image. Follow these steps, Go to store.go in store package. Import your custom resource api package. In init method, add the scheme to your custom resource api. Make sure there are no errors. Rebuild the sensor binary using make sensor To build the image, first change IMAGE_NAMESPACE in Makefile to your docker registry and then run make sensor-image .","title":"How can I add my custom resource as trigger?"}]}