{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Argo Events What is Argo Events? Argo Events is an event-based dependency manager for Kubernetes which helps you define multiple dependencies from a variety of event sources like webhook, s3, schedules, streams etc. and trigger Kubernetes objects after successful event dependencies resolution. Features Manage dependencies from a variety of event sources. Ability to customize business-level constraint logic for event dependencies resolution. Manage everything from simple, linear, real-time dependencies to complex, multi-source, batch job dependencies. Ability to extends framework to add your own event source listener. Define arbitrary boolean logic to resolve event dependencies. CloudEvents compliant. Ability to manage event sources at runtime. Core Concepts The framework is made up of two components: Gateway which is implemented as a Kubernetes-native Custom Resource Definition processes events from event source. Sensor which is implemented as a Kubernetes-native Custom Resource Definition defines a set of event dependencies and triggers K8s resources. Event Source is a configmap that contains configurations which is interpreted by gateway as source for events producing entity. In Nutshell Gateway monitors event sources and starts routines in parallel that consume events from entities like S3, Github, SNS, SQS, PubSub etc. and dispatch these events to sensor. Sensor upon receiving the events, evaluates the dependencies and triggers Argo workflows or other K8s resources.","title":"Overview"},{"location":"#argo-events","text":"","title":"Argo Events"},{"location":"#what-is-argo-events","text":"Argo Events is an event-based dependency manager for Kubernetes which helps you define multiple dependencies from a variety of event sources like webhook, s3, schedules, streams etc. and trigger Kubernetes objects after successful event dependencies resolution.","title":"What is Argo Events?"},{"location":"#features","text":"Manage dependencies from a variety of event sources. Ability to customize business-level constraint logic for event dependencies resolution. Manage everything from simple, linear, real-time dependencies to complex, multi-source, batch job dependencies. Ability to extends framework to add your own event source listener. Define arbitrary boolean logic to resolve event dependencies. CloudEvents compliant. Ability to manage event sources at runtime.","title":"Features"},{"location":"#core-concepts","text":"The framework is made up of two components: Gateway which is implemented as a Kubernetes-native Custom Resource Definition processes events from event source. Sensor which is implemented as a Kubernetes-native Custom Resource Definition defines a set of event dependencies and triggers K8s resources. Event Source is a configmap that contains configurations which is interpreted by gateway as source for events producing entity.","title":"Core Concepts"},{"location":"#in-nutshell","text":"Gateway monitors event sources and starts routines in parallel that consume events from entities like S3, Github, SNS, SQS, PubSub etc. and dispatch these events to sensor. Sensor upon receiving the events, evaluates the dependencies and triggers Argo workflows or other K8s resources.","title":"In Nutshell"},{"location":"communication/","text":"Persisting Events How gateway forwards events to sensor HTTP NATS Standard Streaming How gateway forwards events to sensor? There are two ways an event is dispatched from gateway to sensor: HTTP NATS standard or streaming service HTTP To use HTTP as communication channel between gateway and sensor, you need to configure the eventProtocol in gateway as HTTP. Then, you need to specify the port on which the HTTP server in sensor will be running. The HTTP server is spun up automatically with the port configured in sensor spec when you create the sensor with eventProtocol as HTTP. You don't need to specify address of sensor pod. The sensor pod is exposed through a ClusterIP service. This is taken care by the sensor controller. The name of the sensor service is formatted in a specific way by sensor controller so that gateway can create the service name from sensor name. This is how gateway gets the name of the service exposing sensor. Using the port defined in the spec, gateway makes HTTP POST requests to sensor service. Gateway Example Sensor Example NATS Standard Streaming To use NATS standard or streaming as communication channel between gateway and sensor, you need to configure the eventProtocol in gateway as NATS and type as either Standard or Streaming . You can read more about NATS here In case of NATS, gateway doesn't need to be aware of sensors because the gateway acts as a publisher and sensors act as subscriber. You can store events in external persistent volume. This gives you ability to replay events in future for any reasons. Read more about storing NATS messages here NATS also facilitates the components that are not part of Argo-Events to consume events generated by gateway. For a sensor to consume the events from NATS, the eventProtocol needs to specified as NATS. You can then configure the Standard or Streaming connection detail in eventProtocol . Standard NATS example Gateway Example Sensor Example Streaming NATS example Gateway Example Sensor Example Note : The framework does not provide a NATS installation. You can follow this guide to install NATS onto your cluster.","title":"Persisting Events"},{"location":"communication/#persisting-events","text":"How gateway forwards events to sensor HTTP NATS Standard Streaming","title":"Persisting Events"},{"location":"communication/#how-gateway-forwards-events-to-sensor","text":"There are two ways an event is dispatched from gateway to sensor: HTTP NATS standard or streaming service","title":"How gateway forwards events to sensor?"},{"location":"communication/#http","text":"To use HTTP as communication channel between gateway and sensor, you need to configure the eventProtocol in gateway as HTTP. Then, you need to specify the port on which the HTTP server in sensor will be running. The HTTP server is spun up automatically with the port configured in sensor spec when you create the sensor with eventProtocol as HTTP. You don't need to specify address of sensor pod. The sensor pod is exposed through a ClusterIP service. This is taken care by the sensor controller. The name of the sensor service is formatted in a specific way by sensor controller so that gateway can create the service name from sensor name. This is how gateway gets the name of the service exposing sensor. Using the port defined in the spec, gateway makes HTTP POST requests to sensor service. Gateway Example Sensor Example","title":"HTTP"},{"location":"communication/#nats-standard-streaming","text":"To use NATS standard or streaming as communication channel between gateway and sensor, you need to configure the eventProtocol in gateway as NATS and type as either Standard or Streaming . You can read more about NATS here In case of NATS, gateway doesn't need to be aware of sensors because the gateway acts as a publisher and sensors act as subscriber. You can store events in external persistent volume. This gives you ability to replay events in future for any reasons. Read more about storing NATS messages here NATS also facilitates the components that are not part of Argo-Events to consume events generated by gateway. For a sensor to consume the events from NATS, the eventProtocol needs to specified as NATS. You can then configure the Standard or Streaming connection detail in eventProtocol . Standard NATS example Gateway Example Sensor Example Streaming NATS example Gateway Example Sensor Example Note : The framework does not provide a NATS installation. You can follow this guide to install NATS onto your cluster.","title":"NATS Standard &amp; Streaming"},{"location":"controllers/","text":"Controllers Sensor and Gateway controllers are the components which manage Sensor and Gateway resources respectively. Sensor and Gateway are Kubernetes Custom Resources. For more information on K8 CRDs visit here. Controller configmap Defines the instance-id and the namespace for controller configmap e.g. # The gateway-controller configmap includes configuration information for the gateway-controller apiVersion : v1 kind : ConfigMap metadata : name : gateway-controller-configmap data : config : | instanceID: argo-events # mandatory namespace: my-custom-namespace # optional namespace : If you don't provide namespace, controller will watch all namespaces for gateway resource. instanceID : it is used to map a gateway or sensor to a controller. e.g. when you create a gateway with label gateways.argoproj.io/gateway-controller-instanceid: argo-events , a controller with label argo-events will process that gateway. instanceID for controller are managed using controller-configmap . Basically instanceID is used to horizontally scale controllers, so you won't end up overwhelming a controller with large number of gateways or sensors. Also keep in mind that instanceID has nothing to do with namespace where you are deploying controllers and gateways/sensors. Gateway controller Gateway controller watches gateway resource and manages lifecycle of a gateway. Sensor controller Sensor controller watches sensor resource and manages lifecycle of a sensor.","title":"Controllers"},{"location":"controllers/#controllers","text":"Sensor and Gateway controllers are the components which manage Sensor and Gateway resources respectively. Sensor and Gateway are Kubernetes Custom Resources. For more information on K8 CRDs visit here.","title":"Controllers"},{"location":"controllers/#controller-configmap","text":"Defines the instance-id and the namespace for controller configmap e.g. # The gateway-controller configmap includes configuration information for the gateway-controller apiVersion : v1 kind : ConfigMap metadata : name : gateway-controller-configmap data : config : | instanceID: argo-events # mandatory namespace: my-custom-namespace # optional namespace : If you don't provide namespace, controller will watch all namespaces for gateway resource. instanceID : it is used to map a gateway or sensor to a controller. e.g. when you create a gateway with label gateways.argoproj.io/gateway-controller-instanceid: argo-events , a controller with label argo-events will process that gateway. instanceID for controller are managed using controller-configmap . Basically instanceID is used to horizontally scale controllers, so you won't end up overwhelming a controller with large number of gateways or sensors. Also keep in mind that instanceID has nothing to do with namespace where you are deploying controllers and gateways/sensors.","title":"Controller configmap"},{"location":"controllers/#gateway-controller","text":"Gateway controller watches gateway resource and manages lifecycle of a gateway.","title":"Gateway controller"},{"location":"controllers/#sensor-controller","text":"Sensor controller watches sensor resource and manages lifecycle of a sensor.","title":"Sensor controller"},{"location":"gateway/","text":"Gateway What is a gateway? A gateway consumes events from event sources, transforms them into the cloudevents specification compliant events and dispatches them to sensors. Components A gateway has two components: gateway-client : It creates one or more gRPC clients depending on event sources configurations, consumes events from server, transforms these events into cloudevents and dispatches them to sensors. gateway-server : It is a gRPC server that consumes events from event sources and streams them to gateway client. Core gateways Calendar : Events produced are based on either a cron schedule or an interval duration . In addition, calendar gateway supports a recurrence field in which to specify special exclusion dates for which this gateway will not produce an event. Webhooks : Webhook gateway exposes REST API endpoints. The request received on these endpoints are treated as events. See Request Methods in RFC7231 to define the HTTP REST endpoint. Kubernetes Resources : Resource gateway supports watching Kubernetes resources. Users can specify group , version , kind , and filters including prefix of the object name, labels, annotations, and createdBy time. Artifacts : Artifact gateway supports S3 bucket-notifications via Minio . Note that a supported notification target must be running, exposed. Streams : Stream gateways contain a generic specification for messages received on a queue and/or though messaging server. The following are the stream gateways offered out of box: NATS : Nats is an open-sourced, lightweight, secure, and scalable messaging system for cloud native applications and microservices architecture. It is currently a hosted CNCF Project. MQTT : MMQP is a M2M \"Internet of Things\" connectivity protocol (ISO/IEC PRF 20922) designed to be extremely lightweight and ideal for mobile applications. Some broker implementations can be found here . Kafka : Apache Kafka is a distributed streaming platform. We use Shopify's sarama client for consuming Kafka messages. AMQP : AMQP is a open standard messaging protocol (ISO/IEC 19464). There are a variety of broker implementations including, but not limited to the following: Apache ActiveMQ Apache Qpid StormMQ RabbitMQ You can find core gateways here Community gateways You can find gateways built by the community here . New gateway contributions are always welcome. Example apiVersion : argoproj . io / v1alpha1 kind : Gateway metadata : name : webhook - gateway labels : # gateway controller with instanceId argo-events will process this gateway gateways . argoproj . io / gateway - controller - instanceid : argo - events # gateway controller will use this label to match with it s own version # do not remove argo - events - gateway - version : v0 . 10 spec : type : webhook eventSource : webhook-event-source processorPort : 9330 eventProtocol : type : HTTP http : port : 9300 template : metadata : name : webhook-gateway-http labels : gateway - name : webhook-gateway spec : containers : - name : gateway-client image : argoproj/gateway-client imagePullPolicy : Always command : [ /bin/gateway-client ] - name : webhook-events image : argoproj/webhook-gateway imagePullPolicy : Always command : [ /bin/webhook-gateway ] serviceAccountName : argo-events-sa service : metadata : name : webhook - gateway - svc spec : selector : gateway - name : webhook-gateway ports : - port : 12000 targetPort : 12000 type : LoadBalancer watchers : sensors : - name : webhook-sensor The gateway spec has following fields: type : Type of the gateway. This is defined by the user. eventSource : Refers to K8s configmap that holds the list of event sources. You can use namespace/configmap-name syntax to refer the configmap in a different namespace. processorPort : This is a gateway server port. You can leave this to 9330 unless you really have to change it to a different port. eventProtocol : Communication protocol between sensor and gateway. For more information, head over to communication template : Defines the specification for gateway pod. service : Specification of a K8s service to expose the gateway pod. watchers : List of sensors to which events must be dispatched. Managing Event Sources The event sources configurations are managed using K8s configmap. Once the gateway resource is created with the configmap reference in it's spec, it starts watching the configmap. The gateway-client sends each event source configuration to gateway-server over gRPC. The gateway-server then parses the configuration to start consuming events from external event producing entity. You can modify K8s configmap containing event sources configurations anytime and gateway-client will intelligently pick new/deleted configurations and send them over to gateway-server to either start or stop the event sources. How to write a custom gateway? To implement a custom gateway, you need to create a gRPC server and implement the service defined below. The framework code acts as a gRPC client consuming event stream from gateway server. Proto Definition The proto file is located here If you choose to implement the gateway in Go , then you can find generated client stubs here To create stubs in other languages, head over to gRPC website Service, /** * Service for handling event sources. */ service Eventing { // StartEventSource starts an event source and returns stream of events . rpc StartEventSource ( EventSource ) returns ( stream Event ) ; // ValidateEventSource validates an event source . rpc ValidateEventSource ( EventSource ) returns ( ValidEventSource ) ; } Available Environment Variables to Server Field Description GATEWAY_NAMESPACE K8s namespace of the gateway GATEWAY_EVENT_SOURCE_CONFIG_MAP K8s configmap containing event source GATEWAY_NAME name of the gateway GATEWAY_CONTROLLER_INSTANCE_ID gateway controller instance id GATEWAY_CONTROLLER_NAME gateway controller name GATEWAY_SERVER_PORT Port on which the gateway gRPC server should run Implementation You can follow existing implementations here","title":"Gateway"},{"location":"gateway/#gateway","text":"","title":"Gateway"},{"location":"gateway/#what-is-a-gateway","text":"A gateway consumes events from event sources, transforms them into the cloudevents specification compliant events and dispatches them to sensors.","title":"What is a gateway?"},{"location":"gateway/#components","text":"A gateway has two components: gateway-client : It creates one or more gRPC clients depending on event sources configurations, consumes events from server, transforms these events into cloudevents and dispatches them to sensors. gateway-server : It is a gRPC server that consumes events from event sources and streams them to gateway client.","title":"Components"},{"location":"gateway/#core-gateways","text":"Calendar : Events produced are based on either a cron schedule or an interval duration . In addition, calendar gateway supports a recurrence field in which to specify special exclusion dates for which this gateway will not produce an event. Webhooks : Webhook gateway exposes REST API endpoints. The request received on these endpoints are treated as events. See Request Methods in RFC7231 to define the HTTP REST endpoint. Kubernetes Resources : Resource gateway supports watching Kubernetes resources. Users can specify group , version , kind , and filters including prefix of the object name, labels, annotations, and createdBy time. Artifacts : Artifact gateway supports S3 bucket-notifications via Minio . Note that a supported notification target must be running, exposed. Streams : Stream gateways contain a generic specification for messages received on a queue and/or though messaging server. The following are the stream gateways offered out of box: NATS : Nats is an open-sourced, lightweight, secure, and scalable messaging system for cloud native applications and microservices architecture. It is currently a hosted CNCF Project. MQTT : MMQP is a M2M \"Internet of Things\" connectivity protocol (ISO/IEC PRF 20922) designed to be extremely lightweight and ideal for mobile applications. Some broker implementations can be found here . Kafka : Apache Kafka is a distributed streaming platform. We use Shopify's sarama client for consuming Kafka messages. AMQP : AMQP is a open standard messaging protocol (ISO/IEC 19464). There are a variety of broker implementations including, but not limited to the following: Apache ActiveMQ Apache Qpid StormMQ RabbitMQ You can find core gateways here","title":"Core gateways"},{"location":"gateway/#community-gateways","text":"You can find gateways built by the community here . New gateway contributions are always welcome.","title":"Community gateways"},{"location":"gateway/#example","text":"apiVersion : argoproj . io / v1alpha1 kind : Gateway metadata : name : webhook - gateway labels : # gateway controller with instanceId argo-events will process this gateway gateways . argoproj . io / gateway - controller - instanceid : argo - events # gateway controller will use this label to match with it s own version # do not remove argo - events - gateway - version : v0 . 10 spec : type : webhook eventSource : webhook-event-source processorPort : 9330 eventProtocol : type : HTTP http : port : 9300 template : metadata : name : webhook-gateway-http labels : gateway - name : webhook-gateway spec : containers : - name : gateway-client image : argoproj/gateway-client imagePullPolicy : Always command : [ /bin/gateway-client ] - name : webhook-events image : argoproj/webhook-gateway imagePullPolicy : Always command : [ /bin/webhook-gateway ] serviceAccountName : argo-events-sa service : metadata : name : webhook - gateway - svc spec : selector : gateway - name : webhook-gateway ports : - port : 12000 targetPort : 12000 type : LoadBalancer watchers : sensors : - name : webhook-sensor The gateway spec has following fields: type : Type of the gateway. This is defined by the user. eventSource : Refers to K8s configmap that holds the list of event sources. You can use namespace/configmap-name syntax to refer the configmap in a different namespace. processorPort : This is a gateway server port. You can leave this to 9330 unless you really have to change it to a different port. eventProtocol : Communication protocol between sensor and gateway. For more information, head over to communication template : Defines the specification for gateway pod. service : Specification of a K8s service to expose the gateway pod. watchers : List of sensors to which events must be dispatched.","title":"Example"},{"location":"gateway/#managing-event-sources","text":"The event sources configurations are managed using K8s configmap. Once the gateway resource is created with the configmap reference in it's spec, it starts watching the configmap. The gateway-client sends each event source configuration to gateway-server over gRPC. The gateway-server then parses the configuration to start consuming events from external event producing entity. You can modify K8s configmap containing event sources configurations anytime and gateway-client will intelligently pick new/deleted configurations and send them over to gateway-server to either start or stop the event sources.","title":"Managing Event Sources"},{"location":"gateway/#how-to-write-a-custom-gateway","text":"To implement a custom gateway, you need to create a gRPC server and implement the service defined below. The framework code acts as a gRPC client consuming event stream from gateway server.","title":"How to write a custom gateway?"},{"location":"gateway/#proto-definition","text":"The proto file is located here If you choose to implement the gateway in Go , then you can find generated client stubs here To create stubs in other languages, head over to gRPC website Service, /** * Service for handling event sources. */ service Eventing { // StartEventSource starts an event source and returns stream of events . rpc StartEventSource ( EventSource ) returns ( stream Event ) ; // ValidateEventSource validates an event source . rpc ValidateEventSource ( EventSource ) returns ( ValidEventSource ) ; }","title":"Proto Definition"},{"location":"gateway/#available-environment-variables-to-server","text":"Field Description GATEWAY_NAMESPACE K8s namespace of the gateway GATEWAY_EVENT_SOURCE_CONFIG_MAP K8s configmap containing event source GATEWAY_NAME name of the gateway GATEWAY_CONTROLLER_INSTANCE_ID gateway controller instance id GATEWAY_CONTROLLER_NAME gateway controller name GATEWAY_SERVER_PORT Port on which the gateway gRPC server should run","title":"Available Environment Variables to Server"},{"location":"gateway/#implementation","text":"You can follow existing implementations here","title":"Implementation"},{"location":"getting_started/","text":"Getting Started Lets deploy a webhook gateway and sensor, First, we need to setup event sources for gateway to listen. The event sources for any gateway are managed using K8s configmap. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/event-sources/webhook.yaml Create webhook gateway, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/gateways/webhook.yaml After running above command, gateway controller will create corresponding gateway pod and a LoadBalancing service. Create webhook sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/sensors/webhook.yaml Once sensor resource is created, sensor controller will create corresponding sensor pod and a ClusterIP service. Once the gateway and sensor pods are running, trigger the webhook via a http POST request to /example endpoint. Note: the WEBHOOK_SERVICE_URL will differ based on the Kubernetes cluster. export WEBHOOK_SERVICE_URL=$(minikube service -n argo-events --url webhook-gateway-svc) echo $WEBHOOK_SERVICE_URL curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST $WEBHOOK_SERVICE_URL/example Note : If you are facing an issue getting service url by running minikube service -n argo-events --url webhook-gateway-svc You can use port forwarding to access the service kubectl port-forward Open another terminal window and enter kubectl port-forward -n argo-events name_of_the_webhook_gateway_pod 9003:9330 You can now use localhost:9003 to query webhook gateway Verify that the Argo workflow was run when the trigger was executed. argo list -n argo-events","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"Lets deploy a webhook gateway and sensor, First, we need to setup event sources for gateway to listen. The event sources for any gateway are managed using K8s configmap. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/event-sources/webhook.yaml Create webhook gateway, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/gateways/webhook.yaml After running above command, gateway controller will create corresponding gateway pod and a LoadBalancing service. Create webhook sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/examples/sensors/webhook.yaml Once sensor resource is created, sensor controller will create corresponding sensor pod and a ClusterIP service. Once the gateway and sensor pods are running, trigger the webhook via a http POST request to /example endpoint. Note: the WEBHOOK_SERVICE_URL will differ based on the Kubernetes cluster. export WEBHOOK_SERVICE_URL=$(minikube service -n argo-events --url webhook-gateway-svc) echo $WEBHOOK_SERVICE_URL curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST $WEBHOOK_SERVICE_URL/example Note : If you are facing an issue getting service url by running minikube service -n argo-events --url webhook-gateway-svc You can use port forwarding to access the service kubectl port-forward Open another terminal window and enter kubectl port-forward -n argo-events name_of_the_webhook_gateway_pod 9003:9330 You can now use localhost:9003 to query webhook gateway Verify that the Argo workflow was run when the trigger was executed. argo list -n argo-events","title":"Getting Started"},{"location":"installation/","text":"Installation Requirements Kubernetes cluster v1.9 Installed the kubectl command-line tool v1.9.0 Helm Chart Make sure you have helm client installed and Tiller server is running. To install helm, follow the link. Add argoproj repository helm repo add argo https://argoproj.github.io/argo-helm Install argo-events chart helm install argo/argo-events Using kubectl Deploy Argo Events SA, Roles, ConfigMap, Sensor Controller and Gateway Controller Create the namespace kubectl create namespace argo-events Create the service account kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-sa.yaml Create the cluster roles kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-cluster-roles.yaml Install the sensor custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-crd.yaml Install the gateway custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-crd.yaml Create the confimap for sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-configmap.yaml Create the configmap for gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-configmap.yaml Deploy the sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-deployment.yaml Deploy the gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-deployment.yaml","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#requirements","text":"Kubernetes cluster v1.9 Installed the kubectl command-line tool v1.9.0","title":"Requirements"},{"location":"installation/#helm-chart","text":"Make sure you have helm client installed and Tiller server is running. To install helm, follow the link. Add argoproj repository helm repo add argo https://argoproj.github.io/argo-helm Install argo-events chart helm install argo/argo-events","title":"Helm Chart"},{"location":"installation/#using-kubectl","text":"Deploy Argo Events SA, Roles, ConfigMap, Sensor Controller and Gateway Controller Create the namespace kubectl create namespace argo-events Create the service account kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-sa.yaml Create the cluster roles kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/argo-events-cluster-roles.yaml Install the sensor custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-crd.yaml Install the gateway custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-crd.yaml Create the confimap for sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-configmap.yaml Create the configmap for gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-configmap.yaml Deploy the sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/sensor-controller-deployment.yaml Deploy the gateway controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/master/hack/k8s/manifests/gateway-controller-deployment.yaml","title":"Using kubectl"},{"location":"parameterization/","text":"Trigger Parameterization Payload of an event can be passed to any trigger. Argo Events offers parameterization at two levels, 1) Template 2) Resource Template You can parameterize the template that refers the Argo Worflow / K8s artifact. Resource Allows to parameterize the Argo workflow/K8s resource definition. You can find an example here. Parameter Structure A parameter contains: src : event : the name of the event dependency path : a key within event payload to look for value : default value if sensor can't find path in event payload dest : destination key within resource definition whose corresponding value needs to be replaced with value from event payload operation : what to do with the existing value at dest , either overwrite , prepend , or append","title":"Trigger Parameterization"},{"location":"parameterization/#trigger-parameterization","text":"Payload of an event can be passed to any trigger. Argo Events offers parameterization at two levels, 1) Template 2) Resource","title":"Trigger Parameterization"},{"location":"parameterization/#template","text":"You can parameterize the template that refers the Argo Worflow / K8s artifact.","title":"Template"},{"location":"parameterization/#resource","text":"Allows to parameterize the Argo workflow/K8s resource definition. You can find an example here.","title":"Resource"},{"location":"parameterization/#parameter-structure","text":"A parameter contains: src : event : the name of the event dependency path : a key within event payload to look for value : default value if sensor can't find path in event payload dest : destination key within resource definition whose corresponding value needs to be replaced with value from event payload operation : what to do with the existing value at dest , either overwrite , prepend , or append","title":"Parameter Structure"},{"location":"sensor/","text":"Sensor Sensors define a set of event dependencies (inputs) and triggers (outputs). What is an event dependency? A dependency is an event the sensor is waiting to happen. It is defined as \"gateway-name:event-source-name\". Also, you can use globs to catch a set of events (e.g. \"gateway-name:*\"). What is a dependency group? A dependency group is basically a group of event dependencies. What is a circuit? Circuit is any arbitrary boolean logic that can be applied on dependency groups. What is a trigger? Refer Triggers . How it works? Once the sensor receives an event from gateway either over HTTP or through NATS, it validates the event against dependencies defined in sensor spec. If the event is expected, then it is marked as a valid event and the dependency is marked as resolved. If you haven't defined dependency groups, sensor basically waits for all dependencies to resolve and then kicks off triggers in sequence. If filters are defined, sensor applies the filter on target event and if events pass the filters, triggers are fired. If you have defined dependency groups, sensor upon receiving an event evaluates the group to which the event belongs to and marks the group as resolved if all other event dependencies in the group are already resolved. Whenever a dependency group is resolved, sensor evaluates the circuit defined in spec. If the circuit resolves to true, the triggers are fired. Sensor always waits for circuit to resolve to true before firing triggers. You may not want to fire all the triggers defined in sensor spec. For that, sensor offers when switch on triggers. Basically when switch is way to control when to fire certain trigger depending upon which dependency group is resolved. After sensor fires triggers, it transitions into complete state, increments completion counter and initializes it's state back to running and start the process all over again. Any event that is received in-between are stored on the internal queue. Note : If you don't provide dependency groups and circuit , sensor performs an AND operation on event dependencies. Basic Example Lets look at a basic example, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : webhook - sensor labels : sensors . argoproj . io / sensor - controller - instanceid : argo - events # sensor controller will use this label to match with it s own version # do not remove argo - events - sensor - version : v0 . 10 spec : template : spec : containers : - name : sensor image : argoproj/sensor imagePullPolicy : Always serviceAccountName : argo - events - sa dependencies : - name : webhook-gateway:example eventProtocol : type : HTTP http : port : 9300 triggers : - template : name : webhook - workflow - trigger group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : webhook - spec : entrypoint : whalesay arguments : parameters : - name : message # this is the value that should be overridden value : hello world templates : - name : whalesay inputs : parameters : - name : message container : image : docker / whalesay : latest command : [ cowsay ] args : [ {{inputs.parameters.message}} ] resourceParameters : - src : event : webhook-gateway:example dest : spec . arguments . parameters . 0 . value i. The spec.template.spec defines the template for the sensor pod. ii. The dependencies define list of events the sensor is expected to receive, meaning this is an AND operation. iii. eventProtocol express the mode of communication to receive events from gateways. iv. triggers define list of templates, each containing specification for a K8s resource and optional parameters. Circuit Now, lets look at a more complex example involving a circuit, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : webhook - sensor - http labels : sensors . argoproj . io / sensor - controller - instanceid : argo - events # sensor controller will use this label to match with it s own version # do not remove argo - events - sensor - version : v0 . 10 spec : template : spec : containers : - name : sensor image : argoproj/sensor imagePullPolicy : Always serviceAccountName : argo - events - sa dependencies : - name : webhook-gateway-http:endpoint1 filters : name : context-filter context : source : host : xyz . com contentType : application / json - name : webhook-gateway-http:endpoint2 - name : webhook-gateway-http:endpoint3 - name : webhook-gateway-http:endpoint4 filters : name : data-filter data : - path : bucket type : string value : - argo-workflow-input - argo-workflow-input1 - name : webhook-gateway-http:endpoint5 - name : webhook-gateway-http:endpoint6 - name : webhook-gateway-http:endpoint7 - name : webhook-gateway-http:endpoint8 - name : webhook-gateway-http:endpoint9 dependencyGroups : - name : group_1 dependencies : - webhook-gateway-http:endpoint1 - webhook-gateway-http:endpoint2 - name : group_2 dependencies : - webhook-gateway-http:endpoint3 - name : group_3 dependencies : - webhook-gateway-http:endpoint4 - webhook-gateway-http:endpoint5 - name : group_4 dependencies : - webhook-gateway-http:endpoint6 - webhook-gateway-http:endpoint7 - webhook-gateway-http:endpoint8 - name : group_5 dependencies : - webhook-gateway-http:endpoint9 circuit : group_1 || group_2 || ((group_3 || group_4) group_5) eventProtocol : type : HTTP http : port : 9300 triggers : - template : when : any : - group_1 - group_2 name : webhook - workflow - trigger group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - 1 - spec : entrypoint : whalesay arguments : parameters : - name : message # this is the value that should be overridden value : hello world templates : - name : whalesay inputs : parameters : - name : message container : image : docker / whalesay : latest command : [ cowsay ] args : [ {{inputs.parameters.message}} ] resourceParameters : - src : event : webhook-gateway-http:endpoint1 dest : spec . arguments . parameters . 0 . value - template : name : webhook - workflow - trigger - 2 when : all : - group_5 - group_4 group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - world - 2 - spec : entrypoint : whalesay templates : - name : whalesay container : args : - hello world command : - cowsay image : docker/whalesay:latest - template : name : webhook - workflow - trigger - common group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - world - common - spec : entrypoint : whalesay templates : - name : whalesay container : args : - hello world command : - cowsay image : docker/whalesay:latest The sensor defines the list of dependencies with few containing filters. The filters are explained next. These dependencies are then grouped using dependenciesGroups . The significance of dependenciesGroups is, if you don't define it, the sensor will apply an AND operation and wait for all events to occur. But you may not always want to wait for all the specified events to occur, but rather trigger the workflows as soon as a group or groups of event dependencies are satisfied. To define the logic of when to trigger the workflows, circuit contains a boolean expression that is evaluated every time a event dependency is satisfied. Template can optionally contain when switch that determines when to trigger this template. In the example, the first template will get triggered when either group_1 or group_2 dependencies groups are satisfied, the second template will get triggered only when both group_4 and group_5 are triggered and the last template will be triggered every time the circuit evaluates to true. Execution and Backoff Policy apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : trigger - backoff labels : sensors . argoproj . io / sensor - controller - instanceid : argo - events # sensor controller will use this label to match with it s own version # do not remove argo-events-sensor-version: v0.10 spec: template: spec: containers: - name: sensor image: argoproj/sensor imagePullPolicy: Always serviceAccountName: argo-events-sa dependencies: - name: webhook-gateway-http:foo eventProtocol: type: HTTP http: port: 9300 # If set to true, marks sensor state as `error` if the previous trigger round fails. # Once sensor state is set to `error`, no further triggers will be processed. errorOnFailedRound: true triggers: - template: name: trigger-1 # Policy to configure backoff and execution criteria for the trigger # Because the sensor is able to trigger any K8s resource, it determines the resource state by looking at the resource s labels . policy : # Backoff before checking the resource labels backoff : # Duration is the duration in nanoseconds duration : 1000000000 # 1 second # Duration is multiplied by factor each iteration factor : 2 # The amount of jitter applied each iteration jitter : 0.1 # Exit with error after this many steps steps : 5 # the criteria to decide if a resource is in success or failure state . # labels set on the resource decide if resource is in success or failed state . state : # Note : Set either success or failure labels . If you set both , only success labels will be considered . # Success defines labels required to identify a resource in success state success : workflows . argoproj . io / phase : Succeeded # Failure defines labels required to identify a resource in failed state failure : workflows . argoproj . io / phase : Failed # Determines whether trigger should be marked as failed if the backoff times out and sensor is still unable to decide the state of the trigger . # defaults to false errorOnBackoffTimeout : true group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : webhook - spec : entrypoint : whalesay arguments : parameters : - name : message # this is the value that should be overridden value : hello world templates : - name : whalesay inputs : parameters : - name : message container : image : docker / whalesay : latest command : [ cowsay ] args : [ {{inputs.parameters.message}} ] resourceParameters : - src : event : webhook-gateway-http:foo dest : spec . arguments . parameters . 0 . value - template : name : trigger - 2 policy : backoff : duration : 1000000000 # 1 second factor : 2 jitter : 0.1 steps : 5 state : failure : workflows . argoproj . io / phase : Failed errorOnBackoffTimeout : false group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - world - spec : entrypoint : whalesay templates : - name : whalesay container : image : docker / whalesay : latest command : [ cowsay ] args : [ hello world ] A trigger template can contain execution and backoff policy. Once the trigger is executed by template, it's state is determined using state labels. If labels defined in success criteria matches the subset of labels defined on the resource, the execution is treated as successful and vice-versa for labels defined in failure criteria. Please note that you can only define either success or failure criteria. The backoff directs the sensor on when to check the labels of the executed trigger resource. If after the backoff retries, the sensor is not able to determine the state of the resource, errorOnBackoffTimeout controls whether to mark trigger as failure. The errorOnFailedRound defined outside of triggers decides whether to set the sensor state to error if the previous round of triggers execution fails. Filters You can apply following filters on an event dependency. If the event payload passes the filter, then only it will be treated as a valid event. Type Description Time Filters the signal based on time constraints EventContext Filters metadata that provides circumstantial information about the signal. Data Describes constraints and filters for payload Time Filter filters : time : start : 2016-05-10T15:04:05Z07:00 stop : 2020-01-02T15:04:05Z07:00 Example EventContext Filter filters : context : source : host : amazon . com contentType : application / json Example Data filter filters : data : - path : bucket type : string value : argo - workflow - input Example Examples You can find sensor examples here","title":"Sensor"},{"location":"sensor/#sensor","text":"Sensors define a set of event dependencies (inputs) and triggers (outputs).","title":"Sensor"},{"location":"sensor/#what-is-an-event-dependency","text":"A dependency is an event the sensor is waiting to happen. It is defined as \"gateway-name:event-source-name\". Also, you can use globs to catch a set of events (e.g. \"gateway-name:*\").","title":"What is an event dependency?"},{"location":"sensor/#what-is-a-dependency-group","text":"A dependency group is basically a group of event dependencies.","title":"What is a dependency group?"},{"location":"sensor/#what-is-a-circuit","text":"Circuit is any arbitrary boolean logic that can be applied on dependency groups.","title":"What is a circuit?"},{"location":"sensor/#what-is-a-trigger","text":"Refer Triggers .","title":"What is a trigger?"},{"location":"sensor/#how-it-works","text":"Once the sensor receives an event from gateway either over HTTP or through NATS, it validates the event against dependencies defined in sensor spec. If the event is expected, then it is marked as a valid event and the dependency is marked as resolved. If you haven't defined dependency groups, sensor basically waits for all dependencies to resolve and then kicks off triggers in sequence. If filters are defined, sensor applies the filter on target event and if events pass the filters, triggers are fired. If you have defined dependency groups, sensor upon receiving an event evaluates the group to which the event belongs to and marks the group as resolved if all other event dependencies in the group are already resolved. Whenever a dependency group is resolved, sensor evaluates the circuit defined in spec. If the circuit resolves to true, the triggers are fired. Sensor always waits for circuit to resolve to true before firing triggers. You may not want to fire all the triggers defined in sensor spec. For that, sensor offers when switch on triggers. Basically when switch is way to control when to fire certain trigger depending upon which dependency group is resolved. After sensor fires triggers, it transitions into complete state, increments completion counter and initializes it's state back to running and start the process all over again. Any event that is received in-between are stored on the internal queue. Note : If you don't provide dependency groups and circuit , sensor performs an AND operation on event dependencies.","title":"How it works?"},{"location":"sensor/#basic-example","text":"Lets look at a basic example, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : webhook - sensor labels : sensors . argoproj . io / sensor - controller - instanceid : argo - events # sensor controller will use this label to match with it s own version # do not remove argo - events - sensor - version : v0 . 10 spec : template : spec : containers : - name : sensor image : argoproj/sensor imagePullPolicy : Always serviceAccountName : argo - events - sa dependencies : - name : webhook-gateway:example eventProtocol : type : HTTP http : port : 9300 triggers : - template : name : webhook - workflow - trigger group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : webhook - spec : entrypoint : whalesay arguments : parameters : - name : message # this is the value that should be overridden value : hello world templates : - name : whalesay inputs : parameters : - name : message container : image : docker / whalesay : latest command : [ cowsay ] args : [ {{inputs.parameters.message}} ] resourceParameters : - src : event : webhook-gateway:example dest : spec . arguments . parameters . 0 . value i. The spec.template.spec defines the template for the sensor pod. ii. The dependencies define list of events the sensor is expected to receive, meaning this is an AND operation. iii. eventProtocol express the mode of communication to receive events from gateways. iv. triggers define list of templates, each containing specification for a K8s resource and optional parameters.","title":"Basic Example"},{"location":"sensor/#circuit","text":"Now, lets look at a more complex example involving a circuit, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : webhook - sensor - http labels : sensors . argoproj . io / sensor - controller - instanceid : argo - events # sensor controller will use this label to match with it s own version # do not remove argo - events - sensor - version : v0 . 10 spec : template : spec : containers : - name : sensor image : argoproj/sensor imagePullPolicy : Always serviceAccountName : argo - events - sa dependencies : - name : webhook-gateway-http:endpoint1 filters : name : context-filter context : source : host : xyz . com contentType : application / json - name : webhook-gateway-http:endpoint2 - name : webhook-gateway-http:endpoint3 - name : webhook-gateway-http:endpoint4 filters : name : data-filter data : - path : bucket type : string value : - argo-workflow-input - argo-workflow-input1 - name : webhook-gateway-http:endpoint5 - name : webhook-gateway-http:endpoint6 - name : webhook-gateway-http:endpoint7 - name : webhook-gateway-http:endpoint8 - name : webhook-gateway-http:endpoint9 dependencyGroups : - name : group_1 dependencies : - webhook-gateway-http:endpoint1 - webhook-gateway-http:endpoint2 - name : group_2 dependencies : - webhook-gateway-http:endpoint3 - name : group_3 dependencies : - webhook-gateway-http:endpoint4 - webhook-gateway-http:endpoint5 - name : group_4 dependencies : - webhook-gateway-http:endpoint6 - webhook-gateway-http:endpoint7 - webhook-gateway-http:endpoint8 - name : group_5 dependencies : - webhook-gateway-http:endpoint9 circuit : group_1 || group_2 || ((group_3 || group_4) group_5) eventProtocol : type : HTTP http : port : 9300 triggers : - template : when : any : - group_1 - group_2 name : webhook - workflow - trigger group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - 1 - spec : entrypoint : whalesay arguments : parameters : - name : message # this is the value that should be overridden value : hello world templates : - name : whalesay inputs : parameters : - name : message container : image : docker / whalesay : latest command : [ cowsay ] args : [ {{inputs.parameters.message}} ] resourceParameters : - src : event : webhook-gateway-http:endpoint1 dest : spec . arguments . parameters . 0 . value - template : name : webhook - workflow - trigger - 2 when : all : - group_5 - group_4 group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - world - 2 - spec : entrypoint : whalesay templates : - name : whalesay container : args : - hello world command : - cowsay image : docker/whalesay:latest - template : name : webhook - workflow - trigger - common group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - world - common - spec : entrypoint : whalesay templates : - name : whalesay container : args : - hello world command : - cowsay image : docker/whalesay:latest The sensor defines the list of dependencies with few containing filters. The filters are explained next. These dependencies are then grouped using dependenciesGroups . The significance of dependenciesGroups is, if you don't define it, the sensor will apply an AND operation and wait for all events to occur. But you may not always want to wait for all the specified events to occur, but rather trigger the workflows as soon as a group or groups of event dependencies are satisfied. To define the logic of when to trigger the workflows, circuit contains a boolean expression that is evaluated every time a event dependency is satisfied. Template can optionally contain when switch that determines when to trigger this template. In the example, the first template will get triggered when either group_1 or group_2 dependencies groups are satisfied, the second template will get triggered only when both group_4 and group_5 are triggered and the last template will be triggered every time the circuit evaluates to true.","title":"Circuit"},{"location":"sensor/#execution-and-backoff-policy","text":"apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : trigger - backoff labels : sensors . argoproj . io / sensor - controller - instanceid : argo - events # sensor controller will use this label to match with it s own version # do not remove argo-events-sensor-version: v0.10 spec: template: spec: containers: - name: sensor image: argoproj/sensor imagePullPolicy: Always serviceAccountName: argo-events-sa dependencies: - name: webhook-gateway-http:foo eventProtocol: type: HTTP http: port: 9300 # If set to true, marks sensor state as `error` if the previous trigger round fails. # Once sensor state is set to `error`, no further triggers will be processed. errorOnFailedRound: true triggers: - template: name: trigger-1 # Policy to configure backoff and execution criteria for the trigger # Because the sensor is able to trigger any K8s resource, it determines the resource state by looking at the resource s labels . policy : # Backoff before checking the resource labels backoff : # Duration is the duration in nanoseconds duration : 1000000000 # 1 second # Duration is multiplied by factor each iteration factor : 2 # The amount of jitter applied each iteration jitter : 0.1 # Exit with error after this many steps steps : 5 # the criteria to decide if a resource is in success or failure state . # labels set on the resource decide if resource is in success or failed state . state : # Note : Set either success or failure labels . If you set both , only success labels will be considered . # Success defines labels required to identify a resource in success state success : workflows . argoproj . io / phase : Succeeded # Failure defines labels required to identify a resource in failed state failure : workflows . argoproj . io / phase : Failed # Determines whether trigger should be marked as failed if the backoff times out and sensor is still unable to decide the state of the trigger . # defaults to false errorOnBackoffTimeout : true group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : webhook - spec : entrypoint : whalesay arguments : parameters : - name : message # this is the value that should be overridden value : hello world templates : - name : whalesay inputs : parameters : - name : message container : image : docker / whalesay : latest command : [ cowsay ] args : [ {{inputs.parameters.message}} ] resourceParameters : - src : event : webhook-gateway-http:foo dest : spec . arguments . parameters . 0 . value - template : name : trigger - 2 policy : backoff : duration : 1000000000 # 1 second factor : 2 jitter : 0.1 steps : 5 state : failure : workflows . argoproj . io / phase : Failed errorOnBackoffTimeout : false group : argoproj . io version : v1alpha1 kind : Workflow source : inline : | apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : generateName : hello - world - spec : entrypoint : whalesay templates : - name : whalesay container : image : docker / whalesay : latest command : [ cowsay ] args : [ hello world ] A trigger template can contain execution and backoff policy. Once the trigger is executed by template, it's state is determined using state labels. If labels defined in success criteria matches the subset of labels defined on the resource, the execution is treated as successful and vice-versa for labels defined in failure criteria. Please note that you can only define either success or failure criteria. The backoff directs the sensor on when to check the labels of the executed trigger resource. If after the backoff retries, the sensor is not able to determine the state of the resource, errorOnBackoffTimeout controls whether to mark trigger as failure. The errorOnFailedRound defined outside of triggers decides whether to set the sensor state to error if the previous round of triggers execution fails.","title":"Execution and Backoff Policy"},{"location":"sensor/#filters","text":"You can apply following filters on an event dependency. If the event payload passes the filter, then only it will be treated as a valid event. Type Description Time Filters the signal based on time constraints EventContext Filters metadata that provides circumstantial information about the signal. Data Describes constraints and filters for payload","title":"Filters"},{"location":"sensor/#time-filter","text":"filters : time : start : 2016-05-10T15:04:05Z07:00 stop : 2020-01-02T15:04:05Z07:00 Example","title":"Time Filter"},{"location":"sensor/#eventcontext-filter","text":"filters : context : source : host : amazon . com contentType : application / json Example","title":"EventContext Filter"},{"location":"sensor/#data-filter","text":"filters : data : - path : bucket type : string value : argo - workflow - input Example","title":"Data filter"},{"location":"sensor/#examples","text":"You can find sensor examples here","title":"Examples"},{"location":"trigger/","text":"Trigger What is a trigger? Trigger is the resource executed by sensor once the event dependencies are resolved. Any K8s resource can act as a trigger (Custom Resources included). How to define a trigger? The framework provides support to fetch trigger resources from different sources. Inline Inlined artifacts are included directly within the sensor resource and decoded as a string. Example S3 Argo Events uses the minio-go client for access to any Amazon S3 compatible object store. Example File Artifacts are defined in a file that is mounted via a PersistentVolume within the sensor-controller pod. Example URL Artifacts are accessed from web via RESTful API. Example Configmap Artifacts stored in Kubernetes configmap are accessed using the key. Example Git Artifacts stored in either public or private Git repository. Example Resource Artifacts defined as generic K8s resource template. This is specially useful if you use tools like Kustomize to generate the sensor spec. Example What resource types are supported out of box? Argo Workflow Standard K8s resources Gateway Sensor How to trigger standard Kubernetes Resource instead of Argo Workflow? There could be a case where you may want to trigger a standard Kubernetes resource like Pod, Deployment etc. instead of an Argo Workflow. The sensor allows you to trigger any K8s resource the same way you would trigger an Argo Workflow. The example showcases how you can trigger different standard K8s resources. You can find K8s API reference here . To trigger other standard K8s resources, change the group and version in triggers/resource accordingly. How can I add my custom resource as trigger? The set of currently supported resources are implemented in the store package. You need to register your custom resource in order for sensor to be able to trigger it. Once you register your custom resource, you'll need to rebuild the sensor image. Follow these steps, Go to store.go in store package. Import your custom resource api package. In init method, add the scheme to your custom resource api. Make sure there are no errors. Rebuild the sensor binary using make sensor To build the image, first change IMAGE_NAMESPACE in Makefile to your docker registry and then run make sensor-image .","title":"Trigger"},{"location":"trigger/#trigger","text":"","title":"Trigger"},{"location":"trigger/#what-is-a-trigger","text":"Trigger is the resource executed by sensor once the event dependencies are resolved. Any K8s resource can act as a trigger (Custom Resources included).","title":"What is a trigger?"},{"location":"trigger/#how-to-define-a-trigger","text":"The framework provides support to fetch trigger resources from different sources.","title":"How to define a trigger?"},{"location":"trigger/#inline","text":"Inlined artifacts are included directly within the sensor resource and decoded as a string. Example","title":"Inline"},{"location":"trigger/#s3","text":"Argo Events uses the minio-go client for access to any Amazon S3 compatible object store. Example","title":"S3"},{"location":"trigger/#file","text":"Artifacts are defined in a file that is mounted via a PersistentVolume within the sensor-controller pod. Example","title":"File"},{"location":"trigger/#url","text":"Artifacts are accessed from web via RESTful API. Example","title":"URL"},{"location":"trigger/#configmap","text":"Artifacts stored in Kubernetes configmap are accessed using the key. Example","title":"Configmap"},{"location":"trigger/#git","text":"Artifacts stored in either public or private Git repository. Example","title":"Git"},{"location":"trigger/#resource","text":"Artifacts defined as generic K8s resource template. This is specially useful if you use tools like Kustomize to generate the sensor spec. Example","title":"Resource"},{"location":"trigger/#what-resource-types-are-supported-out-of-box","text":"Argo Workflow Standard K8s resources Gateway Sensor","title":"What resource types are supported out of box?"},{"location":"trigger/#how-to-trigger-standard-kubernetes-resource-instead-of-argo-workflow","text":"There could be a case where you may want to trigger a standard Kubernetes resource like Pod, Deployment etc. instead of an Argo Workflow. The sensor allows you to trigger any K8s resource the same way you would trigger an Argo Workflow. The example showcases how you can trigger different standard K8s resources. You can find K8s API reference here . To trigger other standard K8s resources, change the group and version in triggers/resource accordingly.","title":"How to trigger standard Kubernetes Resource instead of Argo Workflow?"},{"location":"trigger/#how-can-i-add-my-custom-resource-as-trigger","text":"The set of currently supported resources are implemented in the store package. You need to register your custom resource in order for sensor to be able to trigger it. Once you register your custom resource, you'll need to rebuild the sensor image. Follow these steps, Go to store.go in store package. Import your custom resource api package. In init method, add the scheme to your custom resource api. Make sure there are no errors. Rebuild the sensor binary using make sensor To build the image, first change IMAGE_NAMESPACE in Makefile to your docker registry and then run make sensor-image .","title":"How can I add my custom resource as trigger?"},{"location":"gateways/artifact/","text":"Minio S3 The gateway listens to bucket notifications from Minio S3 server. If you are interested in AWS S3 then read AWS SNS Gateway Install Minio If you dont have Minio installed already, follow this link. What types of bucket notifications minio offers? Read about notifications Event Payload Structure Refer AWS S3 Notitification Setup Before you setup gateway and sensor, make sure you have necessary buckets created in Minio. Deploy event source for the gateway. Change the event source configmap according to your use case. Deploy the gateway . Once the gateway pod spins up, check the logs of both gateway-client and artifact-gateway containers and make sure no error occurs. Deploy the sensor . Once the sensor pod spins up, make sure there are no errors in sensor pod. Drop a file onto input bucket and monitor workflows How to add new event source for a different bucket? Simply edit the event source configmap and add new entry that contains the configuration required to listen to new bucket, save the configmap. The gateway will now start listening to both old and new buckets.","title":"Minio S3"},{"location":"gateways/artifact/#minio-s3","text":"The gateway listens to bucket notifications from Minio S3 server. If you are interested in AWS S3 then read AWS SNS Gateway","title":"Minio S3"},{"location":"gateways/artifact/#install-minio","text":"If you dont have Minio installed already, follow this link.","title":"Install Minio"},{"location":"gateways/artifact/#what-types-of-bucket-notifications-minio-offers","text":"Read about notifications","title":"What types of bucket notifications minio offers?"},{"location":"gateways/artifact/#event-payload-structure","text":"Refer AWS S3 Notitification","title":"Event Payload Structure"},{"location":"gateways/artifact/#setup","text":"Before you setup gateway and sensor, make sure you have necessary buckets created in Minio. Deploy event source for the gateway. Change the event source configmap according to your use case. Deploy the gateway . Once the gateway pod spins up, check the logs of both gateway-client and artifact-gateway containers and make sure no error occurs. Deploy the sensor . Once the sensor pod spins up, make sure there are no errors in sensor pod. Drop a file onto input bucket and monitor workflows","title":"Setup"},{"location":"gateways/artifact/#how-to-add-new-event-source-for-a-different-bucket","text":"Simply edit the event source configmap and add new entry that contains the configuration required to listen to new bucket, save the configmap. The gateway will now start listening to both old and new buckets.","title":"How to add new event source for a different bucket?"},{"location":"gateways/aws-sns/","text":"AWS SNS The gateway listens to notifications from AWS SNS. Why is there webhook in the gateway? Because one of the ways you can receive notifications from SNS is over http. So, the gateway runs a http server internally. Once you create an entry in the event source configmap, the gateway will register the url of the server on AWS. All notifications for that topic will then be dispatched by SNS over to the endpoint specified in event source. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server to the outside world. How to get the URL for the service? Depending upon the Kubernetes provider, you can create the Ingress or Route. Setup Deploy gateway before creating event sources because you need to have the gateway pod running and a service backed by the pod, so that you can get the URL for the service. Create the event source . Deploy the sensor . Trigger Workflow As soon as a message is published on your SNS topic, a workflow will be triggered.","title":"AWS SNS"},{"location":"gateways/aws-sns/#aws-sns","text":"The gateway listens to notifications from AWS SNS.","title":"AWS SNS"},{"location":"gateways/aws-sns/#why-is-there-webhook-in-the-gateway","text":"Because one of the ways you can receive notifications from SNS is over http. So, the gateway runs a http server internally. Once you create an entry in the event source configmap, the gateway will register the url of the server on AWS. All notifications for that topic will then be dispatched by SNS over to the endpoint specified in event source. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server to the outside world.","title":"Why is there webhook in the gateway?"},{"location":"gateways/aws-sns/#how-to-get-the-url-for-the-service","text":"Depending upon the Kubernetes provider, you can create the Ingress or Route.","title":"How to get the URL for the service?"},{"location":"gateways/aws-sns/#setup","text":"Deploy gateway before creating event sources because you need to have the gateway pod running and a service backed by the pod, so that you can get the URL for the service. Create the event source . Deploy the sensor .","title":"Setup"},{"location":"gateways/aws-sns/#trigger-workflow","text":"As soon as a message is published on your SNS topic, a workflow will be triggered.","title":"Trigger Workflow"},{"location":"gateways/aws-sqs/","text":"AWS SQS The gateway consumes messages from AWS SQS queue. Setup Deploy the gateway Create the event Source . Because SQS works on polling, you need to provide a waitTimeSeconds . Deploy the sensor . Trigger Workflow As soon as there a message is consumed from SQS queue, a workflow will be triggered.","title":"AWS SQS"},{"location":"gateways/aws-sqs/#aws-sqs","text":"The gateway consumes messages from AWS SQS queue.","title":"AWS SQS"},{"location":"gateways/aws-sqs/#setup","text":"Deploy the gateway Create the event Source . Because SQS works on polling, you need to provide a waitTimeSeconds . Deploy the sensor .","title":"Setup"},{"location":"gateways/aws-sqs/#trigger-workflow","text":"As soon as there a message is consumed from SQS queue, a workflow will be triggered.","title":"Trigger Workflow"},{"location":"gateways/calendar/","text":"Calendar The gateway helps schedule K8s resources on an interval or on a cron schedule. It is solution for triggering any standard or custom K8s resource instead of using CronJob. Setup Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Calendar"},{"location":"gateways/calendar/#calendar","text":"The gateway helps schedule K8s resources on an interval or on a cron schedule. It is solution for triggering any standard or custom K8s resource instead of using CronJob.","title":"Calendar"},{"location":"gateways/calendar/#setup","text":"Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Setup"},{"location":"gateways/file/","text":"File The gateway watches changes to a file within specified directory. Where the directory should be? The directory can be in the pod's own filesystem or you can mount a persistent volume and refer to a directory. Make sure that the directory exists before you create the gateway configmap. Setup Create the event Source . Deploy the gateway . Deploy the sensor . Trigger Workflow Exec into the gateway pod and go to the directory specified in event source and create a file. That should generate an event causing sensor to trigger a workflow. How to listen to notifications from different directories Simply edit the event source configmap and add new entry that contains the configuration required to listen to file within different directory and save the configmap. The gateway will start listening to file notifications from new directory as well.","title":"File"},{"location":"gateways/file/#file","text":"The gateway watches changes to a file within specified directory.","title":"File"},{"location":"gateways/file/#where-the-directory-should-be","text":"The directory can be in the pod's own filesystem or you can mount a persistent volume and refer to a directory. Make sure that the directory exists before you create the gateway configmap.","title":"Where the directory should be?"},{"location":"gateways/file/#setup","text":"Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Setup"},{"location":"gateways/file/#trigger-workflow","text":"Exec into the gateway pod and go to the directory specified in event source and create a file. That should generate an event causing sensor to trigger a workflow.","title":"Trigger Workflow"},{"location":"gateways/file/#how-to-listen-to-notifications-from-different-directories","text":"Simply edit the event source configmap and add new entry that contains the configuration required to listen to file within different directory and save the configmap. The gateway will start listening to file notifications from new directory as well.","title":"How to listen to notifications from different directories"},{"location":"gateways/gcp-pubsub/","text":"GCP PubSub The gateway listens to event streams from google cloud pub sub topics. Make sure to mount credentials file for authentication in gateway pod and refer the path in credentialsFile . Setup Create the event Source . Deploy the gateway . Deploy the sensor . Trigger Workflow As soon as there a message is consumed from PubSub topic, a workflow will be triggered.","title":"GCP PubSub"},{"location":"gateways/gcp-pubsub/#gcp-pubsub","text":"The gateway listens to event streams from google cloud pub sub topics. Make sure to mount credentials file for authentication in gateway pod and refer the path in credentialsFile .","title":"GCP PubSub"},{"location":"gateways/gcp-pubsub/#setup","text":"Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Setup"},{"location":"gateways/gcp-pubsub/#trigger-workflow","text":"As soon as there a message is consumed from PubSub topic, a workflow will be triggered.","title":"Trigger Workflow"},{"location":"gateways/github/","text":"Github The gateway listens to events from GitHub. Events types and webhook Refer here for more information on type of events. Refer here to understand the structure of webhook. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server and make it reachable from GitHub. The event payload dispatched from gateway contains the type of the event in the headers. How to get the URL for the service? Depending upon the Kubernetes provider, you can create the Ingress or Route. Setup Deploy the gateway before creating the event source configmap, because you need to have the gateway pod running and a service backed by the pod, so that you can get the URL for the service. Create the event source . Deploy the Sensor . Trigger Workflow Depending upon the event you subscribe to, a workflow will be triggered.","title":"Github"},{"location":"gateways/github/#github","text":"The gateway listens to events from GitHub.","title":"Github"},{"location":"gateways/github/#events-types-and-webhook","text":"Refer here for more information on type of events. Refer here to understand the structure of webhook. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server and make it reachable from GitHub. The event payload dispatched from gateway contains the type of the event in the headers.","title":"Events types and webhook"},{"location":"gateways/github/#how-to-get-the-url-for-the-service","text":"Depending upon the Kubernetes provider, you can create the Ingress or Route.","title":"How to get the URL for the service?"},{"location":"gateways/github/#setup","text":"Deploy the gateway before creating the event source configmap, because you need to have the gateway pod running and a service backed by the pod, so that you can get the URL for the service. Create the event source . Deploy the Sensor .","title":"Setup"},{"location":"gateways/github/#trigger-workflow","text":"Depending upon the event you subscribe to, a workflow will be triggered.","title":"Trigger Workflow"},{"location":"gateways/gitlab/","text":"Gitlab The gateway listens to events from Gitlab. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server and make it reachable from Gitlab. How to get the URL for the service? Depending upon the Kubernetes provider, you can create the Ingress or Route. Setup Deploy the gateway before creating the event source configmap, because you need to have the gateway pod running and a service backed by the pod, so that you can get the URL for the service. Create the event Source . Deploy the sensor . Trigger Workflow. Depending upon the event you subscribe to, a workflow will be triggered.","title":"Gitlab"},{"location":"gateways/gitlab/#gitlab","text":"The gateway listens to events from Gitlab. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server and make it reachable from Gitlab.","title":"Gitlab"},{"location":"gateways/gitlab/#how-to-get-the-url-for-the-service","text":"Depending upon the Kubernetes provider, you can create the Ingress or Route.","title":"How to get the URL for the service?"},{"location":"gateways/gitlab/#setup","text":"Deploy the gateway before creating the event source configmap, because you need to have the gateway pod running and a service backed by the pod, so that you can get the URL for the service. Create the event Source . Deploy the sensor .","title":"Setup"},{"location":"gateways/gitlab/#trigger-workflow","text":"Depending upon the event you subscribe to, a workflow will be triggered.","title":"Trigger Workflow."},{"location":"gateways/resource/","text":"Resource Resource gateway listens to updates on any Kubernetes resource. Setup Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Resource"},{"location":"gateways/resource/#resource","text":"Resource gateway listens to updates on any Kubernetes resource.","title":"Resource"},{"location":"gateways/resource/#setup","text":"Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Setup"},{"location":"gateways/slack/","text":"Slack The gateway listens to events from Slack. The gateway will not register the webhook endpoint on Slack. You need to manually do it. Setup Deploy the gateway . Create the event Source . Deploy the sensor . Trigger Workflow A workflow will be triggered when slack sends an event.","title":"Slack"},{"location":"gateways/slack/#slack","text":"The gateway listens to events from Slack. The gateway will not register the webhook endpoint on Slack. You need to manually do it.","title":"Slack"},{"location":"gateways/slack/#setup","text":"Deploy the gateway . Create the event Source . Deploy the sensor .","title":"Setup"},{"location":"gateways/slack/#trigger-workflow","text":"A workflow will be triggered when slack sends an event.","title":"Trigger Workflow"},{"location":"gateways/storage-grid/","text":"StorageGrid The gateway listens to bucket notifications from storage grid. Note: The gateway does not register the webhook endpoint on storage grid. You need to do it manually. This is mainly because limitations of storage grid api. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server and make it reachable from StorageGrid. How to get the URL for the service? Depending upon the Kubernetes provider, you can create the Ingress or Route. Setup Deploy the gateway . Create the event Source . Deploy the sensor . Configure notifications Go to your tenant page on StorageGRID Create an endpoint with the following values, and click save Display Name: S3 Notifications URI: route-url-you-created URN: urn:mytext:sns:us-east::my_topic Access Key: your-access-key Secret Key: your-secret-key Certificate Validation: Do not verify Go to the bucket for which you want to configure notifications. Enter the following XML string, and click save NotificationConfiguration TopicConfiguration Id Object-Event /Id Topic urn:mytext:sns:us-east::my_topic /Topic Event s3:ObjectCreated:* /Event Event s3:ObjectRemoved:* /Event /TopicConfiguration /NotificationConfiguration Trigger Workflow Drop a file into the bucket for which you configured the notifications and watch Argo workflow being triggered.","title":"StorageGrid"},{"location":"gateways/storage-grid/#storagegrid","text":"The gateway listens to bucket notifications from storage grid. Note: The gateway does not register the webhook endpoint on storage grid. You need to do it manually. This is mainly because limitations of storage grid api. The gateway spec defined in examples has a serviceSpec . This service is used to expose the gateway server and make it reachable from StorageGrid.","title":"StorageGrid"},{"location":"gateways/storage-grid/#how-to-get-the-url-for-the-service","text":"Depending upon the Kubernetes provider, you can create the Ingress or Route.","title":"How to get the URL for the service?"},{"location":"gateways/storage-grid/#setup","text":"Deploy the gateway . Create the event Source . Deploy the sensor . Configure notifications Go to your tenant page on StorageGRID Create an endpoint with the following values, and click save Display Name: S3 Notifications URI: route-url-you-created URN: urn:mytext:sns:us-east::my_topic Access Key: your-access-key Secret Key: your-secret-key Certificate Validation: Do not verify Go to the bucket for which you want to configure notifications. Enter the following XML string, and click save NotificationConfiguration TopicConfiguration Id Object-Event /Id Topic urn:mytext:sns:us-east::my_topic /Topic Event s3:ObjectCreated:* /Event Event s3:ObjectRemoved:* /Event /TopicConfiguration /NotificationConfiguration","title":"Setup"},{"location":"gateways/storage-grid/#trigger-workflow","text":"Drop a file into the bucket for which you configured the notifications and watch Argo workflow being triggered.","title":"Trigger Workflow"},{"location":"gateways/streams/","text":"Streams A Stream Gateway basically listens to messages on a message queue. The configuration for an event source is somewhat similar between all stream gateways. We will go through setup of NATS gateway. NATS NATS gateway consumes messages by subscribing to NATS topic. Setup Create the event Source . Deploy the gateway . Deploy the sensor . Trigger Workflow Publish message to subject foo . You might find this useful.","title":"Streams"},{"location":"gateways/streams/#streams","text":"A Stream Gateway basically listens to messages on a message queue. The configuration for an event source is somewhat similar between all stream gateways. We will go through setup of NATS gateway.","title":"Streams"},{"location":"gateways/streams/#nats","text":"NATS gateway consumes messages by subscribing to NATS topic.","title":"NATS"},{"location":"gateways/streams/#setup","text":"Create the event Source . Deploy the gateway . Deploy the sensor .","title":"Setup"},{"location":"gateways/streams/#trigger-workflow","text":"Publish message to subject foo . You might find this useful.","title":"Trigger Workflow"},{"location":"gateways/webhook/","text":"Webhook The gateway runs one or more http servers in a pod. Endpoints Endpoints are activate or deactivated at the runtime. The gateway pod continuously monitors the event source configmap. If you add a new endpoint entry in the configmap, the server will register it as an active endpoint and if you remove an endpoint entry, server will mark that endpoint as inactive. Why is there a service spec in gateway spec? Because you'd probably want to expose the gateway to the outside world as gateway pod is running http servers. If you don't to expose the gateway, just remove the serviceSpec from the gateway spec. Setup Create the event source . Deploy the gateway . Deploy the sensor . Trigger Workflow Note: the WEBHOOK_SERVICE_URL will differ based on the Kubernetes cluster. export WEBHOOK_SERVICE_URL=$(minikube service -n argo-events --url gateway_service_name ) echo $WEBHOOK_SERVICE_URL curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST $WEBHOOK_SERVICE_URL/foo Note : If you are facing an issue getting service url by running minikube service -n argo-events --url gateway_service_name , you can use kubectl port-forward Open another terminal window and enter kubectl port-forward -n argo-events name_of_the_webhook_gateway_pod 9003: port_on_which_gateway_server_is_running You can now use localhost:9003 to query webhook gateway","title":"Webhook"},{"location":"gateways/webhook/#webhook","text":"The gateway runs one or more http servers in a pod.","title":"Webhook"},{"location":"gateways/webhook/#endpoints","text":"Endpoints are activate or deactivated at the runtime. The gateway pod continuously monitors the event source configmap. If you add a new endpoint entry in the configmap, the server will register it as an active endpoint and if you remove an endpoint entry, server will mark that endpoint as inactive.","title":"Endpoints"},{"location":"gateways/webhook/#why-is-there-a-service-spec-in-gateway-spec","text":"Because you'd probably want to expose the gateway to the outside world as gateway pod is running http servers. If you don't to expose the gateway, just remove the serviceSpec from the gateway spec.","title":"Why is there a service spec in gateway spec?"},{"location":"gateways/webhook/#setup","text":"Create the event source . Deploy the gateway . Deploy the sensor .","title":"Setup"},{"location":"gateways/webhook/#trigger-workflow","text":"Note: the WEBHOOK_SERVICE_URL will differ based on the Kubernetes cluster. export WEBHOOK_SERVICE_URL=$(minikube service -n argo-events --url gateway_service_name ) echo $WEBHOOK_SERVICE_URL curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST $WEBHOOK_SERVICE_URL/foo Note : If you are facing an issue getting service url by running minikube service -n argo-events --url gateway_service_name , you can use kubectl port-forward Open another terminal window and enter kubectl port-forward -n argo-events name_of_the_webhook_gateway_pod 9003: port_on_which_gateway_server_is_running You can now use localhost:9003 to query webhook gateway","title":"Trigger Workflow"}]}